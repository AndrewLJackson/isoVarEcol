---
title: "Simluate over All Parameters"
output: html_notebook
    
---

```{r setup}

# these packages are required but do not need to be loaded.
# If you do load them, MCMCpack has to be loaded before tidyverse
# else it masks an important function select()
# install.packages(c("SIBER", "MCMCpack"))
# library(SIBER)
# library(MCMCpack)

# these packages are required and need to be loaded.
library(tidyverse)
library(magrittr)
library(broom)
library(patchwork)
library(knitr)
# library(latex2exp) # for latex style equations in figures

# pretty summary table printing these need to be installed, but not loaded
# install.packages("sjplot) # is sufficient to pull the others
# library(sjPlot)
# library(sjmisc)
# library(sjlabelled)




# source the R files while this is not a compiled package
# source("../R/simPopEquilibrium.R")

```


In this file we simulate with variation on all parameters independently. The goal at the end is to test whether the analytical model is capable of explaining the data, and whether correcting for the other paramters can identify the link between variation in diet with variation in consumer isotopes. That is to test whether

$$\sigma_x^2 \propto \sigma_f^2$$

Specifically we simulate data for a single population containing $w$ individuals as follows, and then repeat the process for a number of replicate populations:

The number of sources $K$ is drawn from a uniform distribution within minimum value 2, amd maximum value 20.

$$n \sim \text{Unif(2, 20)}$$

A vector of $K$ $\alpha_i$ values is then created which will define the Dirichlet distribution used to generate the populations. In these simulations we set the number of individuals in each population to be constant at $w = 50$. The numbe

$$\log_{10}(\alpha_i) \sim \text{unif}(-1, 2) $$
Values of $\alpha_i = 1$ for all $K$ sources generate a distribution that is flat on the simplex (although the corresponding marginal distributions are not uniform). Values of $\alpha_i$ all close to 0.1 lower the proabbility density in the middle of the simple and elevate the vertices, while values all close to 10 mean that the pdf has a peak in the centre of the simplex and values near the edges and vertices are relatively unlikely. A vector of $alpha_i$ containing a range of values shift the mode and variance of the pdf on the simplex.

The $w$ individuals comprising the population then have a vector of independent Dirichlet distributed dietary proportions $f_i(w)$

$$f_i(w) \sim \text{Dir}(\alpha_1, \alpha_i, \dots, \alpha_K )$$

A matrix of $j = 2$ isotope values for each of the food sources (the baselines) are simulated from a uniform distribution, from 0 to a maximum value that is itself drawn from a uniform distribution. In this way, the range of each population's food sources differ from each other and hence we simulate a range of variances for the baselines. *Note that we could simulate over different numbers of isotopes by altering the code but for now ewe will stick to two isotope tracers.*

$$x_{ij} \sim \text{unif}(0, \sim \text{unif}(1, 30))$$

Ultimately, the corresponding isotope values of the population of consumers is given by

$$y(w) = \textbf{F}\textbf{X} $$

where $\textbf{F}$ is the $(w \times K)$ matrix of dietary proportions for the entire population $f(w)$ and $\textbf{X*}$ is the $(2 \times K)$ matrix of food source isotope values they consume.

The above procedure is then repeated for each of the 1000 replicate populations.


# Define Population Variance

```{r}
# population variance calculated using cov() and then correcting by 
# multiplying by (n-1) / n
popVar <- function(x){
  
  # sum((x - mean(x)) ^2) / length(x)
  
  x <- as.matrix(x)
  
  n <- nrow(x)
  
  cov(as.matrix(x)) *  (n - 1) / n
  
}


# A basic population variance function
# NB this contrasts with R's default cov() which uses sample variance.
popVar <- function(x){
  
  sum((x - mean(x)) ^2) / length(x)
  
}
```


# Begin Simulations

Define the properties of the consumers

```{r}

# number of isotopes - USER DEFINE and is a key variable we alter for the 
# figures presented in the paper. Specically we present results from 
# n_iso = c(1, 2, 10)
n_iso <- 1

# how many populations to simulate - USER DEFINE
n_pops <- 1000

# how many consumers per population - USER DEFINE
n_individuals <- 100

# Source isotope values range from 0 to source_iso_max 
# and are uniform random. - USER DEFINE
source_iso_max <- 10

# number of food sources they eat from - USER can define the min and max 
# number of food sources
K <- ceiling(runif(n_pops, min = 3, max = 20 ))

# set how many isotopes are used in each population and create the tibble
# that stores the corresponding values of each simulation
# Determined by values defined above.
iso_tbl <- tibble(n_individuals, K, n_iso = rep(n_iso, n_pops) )

```

## Generate the dietary proportions

```{r}

# a function to generate alpha values for input to 
# a corresponding Dirichlet. Values are drawn from a 
# uniform distribution on a log10 scale between 
# min and max as defined in the function call.
generateAlpha <- function(K = 3, min = 0.1, max = 1) {
  
  # return(10 ^ runif(K, min = log10(min), max = log10(max)))
  return(runif(K, min = min, max = max))
  
}


# A function to generate a set of proportions using the 
# alphas defined in generateAlpha
generateProportions <- function(n, K, aa){
  
  return(MCMCpack::rdirichlet(n = n, alpha = aa))
  
}

# Map over the individual simulation values in the tibble and store the 
# corresponding alpha values for the dirichlet distribution.
iso_tbl %<>% mutate(aa = pmap(list(K), generateAlpha, min = 0.1, max = 5 ))

# for testing, can set all alphas == 1
# iso_tbl %<>% mutate(aa = pmap(list(K), generateAlpha, min = 1, max = 1 ))

# use cross_df to set up all combinations, but we have to generate an index
# for the list aa and later insert the corresponding values from aa in 
# the tibble and remove the idx column.
# aj <- cross_df(list(idx = 1:4, K = 1:3))
# bb <- aj %>% mutate(alphas = aa[idx]) %>% select(-idx) 

# Map over the individual simulation values in the tibble and store the 
# corresponding dietary proportions for each simulated population.
iso_tbl %<>% mutate(p = pmap( list(n = n_individuals, K = K, aa = aa), 
                              generateProportions))


```



## Generate the Source isotope values


```{r}

# a wrapper function to pull runifs for the range of source isotoeps
genSourceRange <- function(n_iso, max_val = 30){
  runif(n_iso, min = 0, max = max_val)
  }

## start -- code not run -- retained should S_max be varied across simulations. 
# generate maximum source isotope va?lues from which to draw Sources in the  
# subsequent step.
# iso_tbl %<>% mutate(S_max = pmap(list(n_iso), 
#                                  genSourceRange, 
#                                  max_val = source_iso_max))
# in this formulation S_max is a constant and defined above.
## end -- code not run --

# S_max is same as the user defined constant source_iso_max and in these 
# simulations is a constant. The code immediately above allows this to vary 
# randomly across simluations but there is no real value in pushing this 
# extra source of variation through the code.
iso_tbl %<>% mutate(S_max = source_iso_max)

# a function to generate the sources by drawing them from runif()
generateSources <- function(K = 3, S_max = c(1, 10), setSeed = NULL, ...){
  
  if(!is.null(setSeed)) {set.seed(setSeed)}
  
  # generate a matrix of runif values
  # with K rows and length(S) columns.
  # Each column i has runif max = S_max[i]
  matrix(runif(n = K * length(S_max), min = 0, max = S_max),
         ncol = length(S_max), byrow = TRUE)
  
  ## for debugging
  # print(c(K,S_max)) 
  
}


# ------------------------------------------------------------------------------

# use pmap to loop over the rows of our tibble, select the K and S_max
# columns and use those to draw a set of runif distributed isotope values for
# each of the K sources and number of isotopes (length of S_max)
iso_tbl %<>% mutate(X = pmap( list(K, S_max), generateSources, setSeed = NULL))



```


## Calculate consumer isotope values

A function to generate the consumer isotope values

```{r}
simPopEquilibrium <- function(p = MCMCpack::rdirichlet(1, rep(1, 3)),
                              S = matrix(runif(6, min = -10, max = 0),
                                         nrow = 3, ncol = 2), TDF = 0, ...) {

  

  # Calculate the Stable isotope values of the consumers as a
  # p weighted sum of food source isotoep values (S) after applying the
  # Trophic Discrimination factor (TDF)
  consumerIso <- p %*% (S + TDF)

  return(consumerIso)
}

```


```{r}

# call the function simPopEquilibrium. 
# This function calculates the consumer isotope values.
# This function is mapped over each row in our dataset and 
# takes the dietary proportions p and source isotope values S.
iso_tbl %<>% mutate(Y = pmap(list(p, X), simPopEquilibrium))


```


# Calculate Variances of the Simulated Data

This function below allows us to calculate the mean, variance and covariance of the dirichlet distribution used to simulate each population's dietary proportions. *Currently not used in subsequent analyses.*

```{r dirichlet-moments}

# given a vector of alphas calculate the first moments
dirichletMomentsAlphas <- function(aa) {
  
  # sum of alphas used as shorthand subsequently
  a_0 <- sum(aa)
  
  # the mean
  mu_X <- aa / a_0
  
  # variance
  var_X <- aa * (aa - a_0) / (a_0^2 * (a_0 + 1))
  
  # covariance
  a_ij <- aa %*% t(aa)
  diag(a_ij) <- 0 # set i=j to zero
  
  cov_X <- -a_ij / (a_0^2 * (a_0 + 1))
  
  return(list(mu_X, var_X, cov_X))
  
  
}
  

# Debuggin - test the function
# dirichletMomentsAlphas(rep(3, 5))
                        
```


There are numerous ways in which variance can be calculated on these multivariate data. In particular the dietary proportions causes most difficulty owing to the strict negative covariances on the simplex. The approach taken currently is to calculate the sum of the marginal variances only; i.e. to ignore the off-diagonal covariances (this is the Trace of the matrix of dietary proportions $\text{tr}(\textbf{F})$).

We also calculate some statistical descriptors of the variance among consumer isotope values within each simulated popultion. The Standard Ellipse Area (SEA) is calculated here but currently not used in the visualisations below (*incidentally its interesting how SEA does not correlate well with \sigma_x*). The total variance among consumers' isotope values withiin a population is calculated as the sum of the covariance matrix of the samples $\hat{\sigma_x} = \sum\text{cov(x)}$.

The total variance of the isotope food sources for each population is calculated in the same way $\hat{\sigma_{x^*}} = \sum\text{cov}(x^*)$.



```{r}

# Use pmap to calculate various summary statistics for each population (row) 
# based on the dietary proportions. 

iso_tbl %<>%
  mutate(p_cov = pmap(list(p), ~cov(.)),
         p_trace = pmap(list(p), ~unlist(sum(diag(cov(.))))) %>% unlist,
         p_eig_values = pmap(list(p), ~eigen(cov(.))$values),
         p_aniso      = pmap(list(p), ~diff(c(min(eigen(cov(.))$values),
                                              max(eigen(cov(.))$values)))) %>%
           unlist,
         )

# # testing with jeff's code
# iso_tbl %<>% 
#   mutate(p_mean_sigma = map(p_eig_values, ~mean(.[-length(.)])) %>% unlist)
# iso_tbl %<>% 
#   mutate(X_theo = K * p_mean_sigma)


# A function to call and extract the area of the 
# Standard Ellipse Area of the isotope data
# NB only works in two dimensions for SIBER but it can easily be 
# extended to Z dimensions. We use an internal if() statement to check 
# before calculating the area, else it returns NA.
doSEA <- function(x) {
  if(ncol(x) == 2) {
    out <- SIBER::sigmaSEA(cov(x))$SEA
  
  } else {
  out <- NA
  }
  return(out)
}

# function to calculate Jeff's var_x
# np.dot(x_star,np.dot(C,x_star))
consumerVarEstimate <- function(S, p_cov){
  
  out <- t(S) %*% (p_cov %*% S)
  return(out)
}

# Calculate various summary statistics of consumer isotope variation
iso_tbl %<>% 
  mutate(SEA     = pmap(list(Y), ~doSEA(.)) %>% unlist,
         Y_var   = pmap(list(Y), ~sum(apply(., 2, popVar))) %>% unlist,
         Y_trace = pmap(list(Y), ~sum(diag(popVar(.)))) %>% unlist
         )

# test jeff's model specification
# iso_tbl %<>% mutate(X_jeff  = pmap(list(S, p_cov), consumerVarEstimate) %>% unlist)


# Calculate various statistics on the Source variation including the 
# sum of the covariance matrix and its trace.
iso_tbl %<>% 
  mutate(X_var   = pmap(list(X), ~sum(apply(., 2, popVar))) %>% unlist,
         X_trace = pmap(list(X), ~sum(diag(popVar(.))))     %>% unlist)



```


## Plot the simluations



```{r}

# generate the string for the figure title
my_title <- ifelse(n_iso == 1, 
                   paste0(n_iso, " isotope"),
                   paste0(n_iso, " isotopes"))

# uncorrected X_var
g1 <- ggplot(data = iso_tbl, 
             mapping = aes(x = p_trace,
                           y = Y_var)) + 
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm") + 
  ggtitle(my_title) + 
  xlab(expression(Tr(italic(C[f])))) + 
  ylab(expression(var(italic(y))))

# (K / (K-1))

# corrected X_var
g1_corrected <- ggplot(data = iso_tbl, 
             mapping = aes(x = ((K) / (K-1)) * p_trace,
                           y = Y_var / X_var)) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  scale_color_viridis_c() + 
  ggtitle(my_title) + 
  coord_equal() + 
  xlim(0, 0.2) + 
  ylim(0, 0.2) + 
  xlab(expression(italic(frac(n, n-1))* Tr(italic(C[f])))) + 
  ylab(expression(var(italic(y)) / var(italic(x))))
  
  
g1_test <- g1_corrected + aes(x = p_trace)


(g1 | g1_corrected)

ggsave(plot = (g1),
       paste0("../export/", "n_iso_", n_iso, "_naive_correlation.pdf"), 
       width = 7, height = 7)
ggsave(plot = (g1_corrected), 
       filename = paste0("../export/", "n_iso_", n_iso, "_corrected_correlation.pdf"), 
       width = 7, height = 7)
```


```{r}

g2 <- ggplot(iso_tbl, aes(x = K * p_aniso,
                          y = (Y_var / X_var) - (K / (K-1)) * p_trace )) + 
  geom_point(alpha = 0.5)

# absolute deviations
g2_abs <- g2 + aes(y = abs((Y_var / X_var) - (K / (K-1)) * p_trace )) + 
  geom_smooth(method = "lm") + 
  ylab("Absolute Deviance") + 
  xlab(expression(n (aniso_equation)))

(g2_abs)

ggsave(g2_abs, 
       filename = paste0("../export/", "n_iso_", n_iso, "_anisotropy.pdf"), 
       width = 10, height = 4.51)

```


### Fit a linear model for all the variables

The prediction from a log-log regression model would be that the coefficients are all equal to 1. This is because on a log-log scale, the multiplicative relationships become additive. That is, if 

$$y = abc$$

then

$$\log(y) = \log(a) + \log(b) + \log(c)$$

**_I'm quite surprised with these results. Given that the glm() model is fitting type 3 sums of squares (fully partial residuals) I would have expected all of the slopes to very close to 1 given the figures above._**

```{r}

m5 <- glm(log(Y_var) ~ log(I(K/(K-1))) + log(X_var) + log(p_trace), data = iso_tbl)

m5 %>% tidy() %>% kable(digits = 2)
```


## Testing

How do the sum of the covariance matrices (for $Y$ and $X$) correlate with its trace?
 
```{r}
ggplot(iso_tbl, aes(x = Y_var, y = Y_trace)) + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  geom_smooth(method = "lm")


ggplot(iso_tbl, aes(x = X_var, y = X_trace)) + 
  geom_point() + 
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  geom_smooth(method = "lm")

```











